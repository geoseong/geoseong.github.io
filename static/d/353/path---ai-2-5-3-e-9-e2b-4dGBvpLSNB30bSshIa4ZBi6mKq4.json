{"pageContext":{"isCreatedByStatefulCreatePages":false,"notebook":"AI","section":"딥러닝","page":{"id":"0-68f05c3339ecb44cb19333271fa90935!1-BC575AB8E2AB9833!2201","self":"https://www.onenote.com/api/v1.0/me/notes/pages/0-68f05c3339ecb44cb19333271fa90935!1-BC575AB8E2AB9833!2201","createdTime":"2018-02-03T03:34:09Z","title":"04 : Linear Regression 구현","createdByAppId":"","links":{"oneNoteEmbedUrl":{"href":"https://onedrive.live.com/redir.aspx?cid=bc575ab8e2ab9833&page=edit&resid=BC575AB8E2AB9833!2197&parId=BC575AB8E2AB9833!109&wd=target%28%EB%94%A5%EB%9F%AC%EB%8B%9D.one%7C201f07a6-a1e3-504b-ba05-875cb8a446f7%2F04%20%20Linear%20Regression%20%EA%B5%AC%ED%98%84%7Cb3cdf1e0-ed41-3f44-82d3-887c61d876c5%2F%29"},"oneNoteClientUrl":{"href":"onenote:https://d.docs.live.net/bc575ab8e2ab9833/Documents/AI/%EB%94%A5%EB%9F%AC%EB%8B%9D.one#04%20%20Linear%20Regression%20%EA%B5%AC%ED%98%84&section-id=201f07a6-a1e3-504b-ba05-875cb8a446f7&page-id=b3cdf1e0-ed41-3f44-82d3-887c61d876c5&end"},"oneNoteWebUrl":{"href":"https://onedrive.live.com/redir.aspx?cid=bc575ab8e2ab9833&page=edit&resid=BC575AB8E2AB9833!2197&parId=BC575AB8E2AB9833!109&wd=target%28%EB%94%A5%EB%9F%AC%EB%8B%9D.one%7C201f07a6-a1e3-504b-ba05-875cb8a446f7%2F04%20%20Linear%20Regression%20%EA%B5%AC%ED%98%84%7Cb3cdf1e0-ed41-3f44-82d3-887c61d876c5%2F%29"}},"contentUrl":"https://www.onenote.com/api/v1.0/me/notes/pages/0-68f05c3339ecb44cb19333271fa90935!1-BC575AB8E2AB9833!2201/content","lastModifiedTime":"2018-03-03T03:18:08Z","parentSection@odata.context":"https://www.onenote.com/api/v1.0/$metadata#me/notes/sections('0-BC575AB8E2AB9833%212201')/pages('0-68f05c3339ecb44cb19333271fa90935%211-BC575AB8E2AB9833%212201')/parentSection(id,name,self)/$entity","parentSection":{"id":"0-BC575AB8E2AB9833!2201","name":"딥러닝","self":"https://www.onenote.com/api/v1.0/me/notes/sections/0-BC575AB8E2AB9833!2201"},"content":"       목차    Case 1. 명시적으로 입력데이터를 주어서 코딩하기    Case 2. placeholder를 사용해서 구현하기            Case1. 명시적으로 입력데이터를 주어서 코딩하기        [pic1]    Linear Regression 수학공식을 tensorflow코딩으로 옮기는 작업.    Tf.random_normal([1]) : 값이 하나인 1차원 함수를 쓰겠다.            [pic2]    그래프를 구현    learning_rate=0.01 : ??    Cost를 최소화 시키기 = GradientDescent & minimize                [pic3]    노드 실행하기            그래프 구조            실제 작성했던 Full Code        >>> import tensorflow as tf    >>> x_train = [1,2,3]    >>> y_train = [1,2,3]    >>> W = tf.Variable(tf.random_normal([1]), name='weight')    >>> b = tf.Variable(tf.random_normal([1]), name='bias')    >>> hypothesis = x_train * W + b    >>> cost = tf.reduce_mean(tf.square(hypothesis - y_train))    >>> optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)    >>> train = optimizer.minimize(cost)    >>> sess = tf.Session()    2018-02-03 12:37:08.182417: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX    >>> sess.run(tf.global_variables_initializer())    >>> for step in range(2001):    ...     sess.run(train)    ...     if step % 20 == 0:    ...             print(step, sess.run(cost), sess.run(W), sess.run(b))        실행결과    0 3.713712 [0.02278715] [0.2002644]    20 0.06962725 [0.7077251] [0.47195536]    40 0.033287223 [0.7823072] [0.47654152]    60 0.029960474 [0.7983317] [0.45669454]    80 0.027208129 [0.808361] [0.43547428]    100 0.024710855 [0.8174199] [0.41503173]    120 0.02244278 [0.82600546] [0.395529]    140 0.020382902 [0.834183] [0.37694082]    160 0.018512083 [0.84197587] [0.35922602]    180 0.01681295 [0.8494024] [0.34234372]    200 0.015269786 [0.85647994] [0.32625479]    220 0.013868277 [0.8632249] [0.310922]    240 0.012595397 [0.86965275] [0.2963099]    260 0.011439345 [0.87577856] [0.28238443]    280 0.010389394 [0.88161653] [0.26911345]    300 0.00943583 [0.88718003] [0.25646618]    320 0.008569776 [0.89248216] [0.24441324]    340 0.007783193 [0.89753515] [0.23292676]    360 0.007068824 [0.9023506] [0.22198005]    380 0.0064200214 [0.9069397] [0.21154784]    400 0.00583077 [0.9113132] [0.20160589]    420 0.0052955956 [0.91548115] [0.19213118]    440 0.0048095514 [0.9194533] [0.18310168]    460 0.0043681073 [0.92323864] [0.17449658]    480 0.003967175 [0.92684615] [0.16629589]    500 0.0036030663 [0.9302841] [0.15848066]    520 0.0032723574 [0.9335605] [0.15103266]    540 0.0029720112 [0.93668294] [0.14393467]    560 0.0026992324 [0.9396585] [0.1371703]    580 0.002451485 [0.9424944] [0.13072379]    600 0.0022264798 [0.945197] [0.12458024]    620 0.002022121 [0.9477725] [0.11872541]    640 0.0018365212 [0.95022696] [0.11314581]    660 0.0016679593 [0.95256615] [0.10782836]    680 0.0015148661 [0.95479536] [0.10276081]    700 0.001375829 [0.95691985] [0.09793143]    720 0.0012495482 [0.9589444] [0.09332903]    740 0.0011348572 [0.9608739] [0.08894292]    760 0.0010307012 [0.96271265] [0.08476292]    780 0.00093610043 [0.964465] [0.08077938]    800 0.00085018 [0.96613497] [0.07698306]    820 0.00077214325 [0.9677265] [0.07336518]    840 0.0007012772 [0.9692432] [0.06991728]    860 0.0006369103 [0.97068876] [0.06663139]    880 0.0005784516 [0.9720662] [0.06349993]    900 0.00052535906 [0.973379] [0.06051568]    920 0.0004771402 [0.97463024] [0.05767165]    940 0.0004333457 [0.97582245] [0.05496129]    960 0.00039357066 [0.9769587] [0.0523783]    980 0.0003574485 [0.9780415] [0.04991673]    1000 0.00032464007 [0.9790734] [0.04757087]    1020 0.00029484302 [0.9800569] [0.04533525]    1040 0.0002677821 [0.9809942] [0.04320465]    1060 0.00024320187 [0.98188746] [0.04117415]    1080 0.00022088036 [0.9827387] [0.03923912]    1100 0.00020060735 [0.98354983] [0.03739504]    1120 0.00018219619 [0.9843229] [0.03563761]    1140 0.00016547373 [0.9850597] [0.03396281]    1160 0.00015028403 [0.9857619] [0.03236667]    1180 0.00013649119 [0.986431] [0.03084555]    1200 0.00012396318 [0.9870687] [0.02939592]    1220 0.00011258564 [0.9876764] [0.02801441]    1240 0.00010225103 [0.98825556] [0.02669785]    1260 9.286816e-05 [0.98880756] [0.02544314]    1280 8.4343854e-05 [0.98933345] [0.02424742]    1300 7.660236e-05 [0.9898347] [0.02310794]    1320 6.95713e-05 [0.9903125] [0.022022]    1340 6.318514e-05 [0.9907678] [0.02098702]    1360 5.7386787e-05 [0.9912017] [0.02000071]    1380 5.212003e-05 [0.9916152] [0.01906073]    1400 4.7335576e-05 [0.9920092] [0.01816494]    1420 4.299082e-05 [0.9923848] [0.01731124]    1440 3.90451e-05 [0.9927426] [0.01649767]    1460 3.5461682e-05 [0.9930837] [0.01572235]    1480 3.220665e-05 [0.99340874] [0.01498345]    1500 2.9250457e-05 [0.9937185] [0.01427927]    1520 2.6565473e-05 [0.9940137] [0.0136082]    1540 2.4127477e-05 [0.99429506] [0.01296867]    1560 2.1912982e-05 [0.99456316] [0.01235919]    1580 1.9901623e-05 [0.9948187] [0.01177835]    1600 1.8075167e-05 [0.9950623] [0.01122481]    1620 1.641594e-05 [0.99529433] [0.01069723]    1640 1.4908433e-05 [0.99551547] [0.01019447]    1660 1.3540203e-05 [0.9957262] [0.00971535]    1680 1.2297666e-05 [0.9959271] [0.00925876]    1700 1.1168816e-05 [0.9961185] [0.00882361]    1720 1.0143584e-05 [0.99630094] [0.00840892]    1740 9.212734e-06 [0.99647474] [0.00801373]    1760 8.367361e-06 [0.9966404] [0.00763713]    1780 7.5992216e-06 [0.9967983] [0.00727822]    1800 6.9017074e-06 [0.9969488] [0.00693617]    1820 6.2684885e-06 [0.9970922] [0.00661019]    1840 5.693173e-06 [0.9972288] [0.00629954]    1860 5.170363e-06 [0.9973591] [0.00600348]    1880 4.6960135e-06 [0.99748313] [0.00572136]    1900 4.265188e-06 [0.9976014] [0.0054525]    1920 3.8732032e-06 [0.99771416] [0.00519625]    1940 3.5180622e-06 [0.99782157] [0.00495204]    1960 3.1948596e-06 [0.997924] [0.00471931]    1980 2.9017058e-06 [0.99802154] [0.00449752]    2000 2.6356656e-06 [0.99811447] [0.00428616]        결과설명                    Case 2. placeholder를 사용해서 구현하기        [pic1]                [pic2]    [None]의 None : 아무 값이나 와도 된다는 뜻.               ","html":"\n\t\t<div style=\"position:absolute;left:48px;top:139px;width:576px\">\n\t\t\t<h1 lang=\"ko-KR\" style=\"font-size:16pt;color:#1e4e79;margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Malgun Gothic\">&#xBAA9;&#xCC28;</span></h1>\n\t\t\t<h3 style=\"color:#5b9bd5;margin-top:0pt;margin-bottom:0pt\">Case 1. <span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xBA85;&#xC2DC;&#xC801;&#xC73C;&#xB85C;</span> <span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xC785;&#xB825;&#xB370;&#xC774;&#xD130;&#xB97C;</span> <span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xC8FC;&#xC5B4;&#xC11C;</span> <span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xCF54;&#xB529;&#xD558;&#xAE30;</span></h3>\n\t\t\t<h3 style=\"color:#5b9bd5;margin-top:0pt;margin-bottom:0pt\">Case 2. placeholder<span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xB97C;</span> <span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xC0AC;&#xC6A9;&#xD574;&#xC11C;</span> <span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xAD6C;&#xD604;&#xD558;&#xAE30;</span></h3>\n\t\t\t<br>\n\t\t\t<br>\n\t\t\t<h1 style=\"font-size:16pt;color:#1e4e79;margin-top:0pt;margin-bottom:0pt\">Case1. <span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xBA85;&#xC2DC;&#xC801;&#xC73C;&#xB85C;</span><span style=\"font-family:Malgun Gothic\"> </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xC785;&#xB825;&#xB370;&#xC774;&#xD130;&#xB97C;</span><span style=\"font-family:Malgun Gothic\"> </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xC8FC;&#xC5B4;&#xC11C;</span><span style=\"font-family:Malgun Gothic\"> </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xCF54;&#xB529;&#xD558;&#xAE30;</span></h1>\n\t\t\t<br>\n\t\t\t<h2 style=\"font-size:14pt;color:#2e75b5;margin-top:0pt;margin-bottom:0pt\">[pic1]</h2>\n\t\t\t<p style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Malgun Gothic\">Linear Regression </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xC218;&#xD559;&#xACF5;&#xC2DD;&#xC744;</span><span style=\"font-family:Malgun Gothic\"> tensorflow</span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xCF54;&#xB529;&#xC73C;&#xB85C;</span><span style=\"font-family:Malgun Gothic\"> </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xC62E;&#xAE30;&#xB294;</span><span style=\"font-family:Malgun Gothic\"> </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xC791;&#xC5C5;</span><span style=\"font-family:Malgun Gothic\">.</span></p>\n\t\t\t<p style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Malgun Gothic;font-weight:bold\">Tf.random_normal([1])</span><span style=\"font-family:Malgun Gothic\"> : </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xAC12;&#xC774;</span><span style=\"font-family:Malgun Gothic\"> </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xD558;&#xB098;&#xC778;</span><span style=\"font-family:Malgun Gothic\"> 1</span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xCC28;&#xC6D0;</span><span style=\"font-family:Malgun Gothic\"> </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xD568;&#xC218;&#xB97C;</span><span style=\"font-family:Malgun Gothic\"> </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xC4F0;&#xACA0;&#xB2E4;</span><span style=\"font-family:Malgun Gothic\">.</span></p>\n\t\t\t<img alt=\"O Build graph using T F operal \n# X and Y data \nx train = \ny_train \nname- &#x2022; weight ) \nname&#x2014; &#x2022; bias ) \n# Our hypothesis XW+b \nypothesis = x _ train * + b \" width=\"480\" height=\"279\" src=\"https://www.onenote.com/api/v1.0/me/notes/resources/0-77854471d85fc546b388ad28ec349e0a!1-BC575AB8E2AB9833!2201/content?publicAuth=true&amp;mimeType=image/png\" data-src-type=\"image/png\" data-fullres-src=\"https://www.onenote.com/api/v1.0/me/notes/resources/0-77854471d85fc546b388ad28ec349e0a!1-BC575AB8E2AB9833!2201/content?publicAuth=true&amp;mimeType=image/png\" data-fullres-src-type=\"image/png\">\n\t\t\t<br>\n\t\t\t<h2 style=\"font-size:14pt;color:#2e75b5;margin-top:0pt;margin-bottom:0pt\">[pic2]</h2>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Malgun Gothic\">&#xADF8;&#xB798;&#xD504;&#xB97C;</span><span lang=\"en-US\" style=\"font-family:Malgun Gothic\"> </span><span style=\"font-family:Malgun Gothic\">&#xAD6C;&#xD604;</span></p>\n\t\t\t<p style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Malgun Gothic;font-weight:bold\">learning_rate=0.01</span><span style=\"font-family:Malgun Gothic\"> : ??</span></p>\n\t\t\t<p style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Malgun Gothic;font-weight:bold\">Cost</span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic;font-weight:bold\">&#xB97C;</span><span style=\"font-family:Malgun Gothic;font-weight:bold\"> </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic;font-weight:bold\">&#xCD5C;&#xC18C;&#xD654;</span><span style=\"font-family:Malgun Gothic;font-weight:bold\"> </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic;font-weight:bold\">&#xC2DC;&#xD0A4;&#xAE30;</span><span style=\"font-family:Malgun Gothic\"> = GradientDescent &amp; minimize</span></p>\n\t\t\t<img alt=\"O Build graph using T F opera \n2. \nt . reduce \n# cost/Loss function \nc st tf. square(hypothesis - y _ train)) \nGradientDescent \" width=\"480\" height=\"273\" src=\"https://www.onenote.com/api/v1.0/me/notes/resources/0-c1d57be5dffd12459c3a969955d7d3da!1-BC575AB8E2AB9833!2201/content?publicAuth=true&amp;mimeType=image/png\" data-src-type=\"image/png\" data-fullres-src=\"https://www.onenote.com/api/v1.0/me/notes/resources/0-c1d57be5dffd12459c3a969955d7d3da!1-BC575AB8E2AB9833!2201/content?publicAuth=true&amp;mimeType=image/png\" data-fullres-src-type=\"image/png\">\n\t\t\t<br>\n\t\t\t<br>\n\t\t\t<h2 style=\"font-size:14pt;color:#2e75b5;margin-top:0pt;margin-bottom:0pt\">[pic3]</h2>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Malgun Gothic\">&#xB178;&#xB4DC;</span><span lang=\"en-US\" style=\"font-family:Malgun Gothic\"> </span><span style=\"font-family:Malgun Gothic\">&#xC2E4;&#xD589;&#xD558;&#xAE30;</span></p>\n\t\t\t<img alt=\"O Run/update graph and gel \n# Launch the graph in a session. \nsess = tf.Session() \n# Initializes global variables in the graph. \n# Fit the Line \" width=\"480\" height=\"282\" src=\"https://www.onenote.com/api/v1.0/me/notes/resources/0-4b4a2adb68009b48b4efc893bb522bac!1-BC575AB8E2AB9833!2201/content?publicAuth=true&amp;mimeType=image/png\" data-src-type=\"image/png\" data-fullres-src=\"https://www.onenote.com/api/v1.0/me/notes/resources/0-4b4a2adb68009b48b4efc893bb522bac!1-BC575AB8E2AB9833!2201/content?publicAuth=true&amp;mimeType=image/png\" data-fullres-src-type=\"image/png\">\n\t\t\t<br>\n\t\t\t<h2 lang=\"ko-KR\" style=\"font-size:14pt;color:#2e75b5;margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Malgun Gothic\">&#xADF8;&#xB798;&#xD504;</span><span lang=\"en-US\"> </span><span style=\"font-family:Malgun Gothic\">&#xAD6C;&#xC870;</span></h2>\n\t\t\t<img alt=\"tt6tze&#x2022;t-l tswszzsv&#x2022;t zs&#x20AC;tst&#x2022;a \n36sese&#x2022;t-l ttegt6E&#x20AC;s&#x2022;t tS06t&#x2022;e et \n(996Ezsg&#x2022;e-J [ElLL98Zt&#x2022;z e \" width=\"372\" height=\"351\" src=\"https://www.onenote.com/api/v1.0/me/notes/resources/0-93c25b0817e2034dba2a404b4b1219df!1-BC575AB8E2AB9833!2201/content?publicAuth=true&amp;mimeType=image/png\" data-src-type=\"image/png\" data-fullres-src=\"https://www.onenote.com/api/v1.0/me/notes/resources/0-93c25b0817e2034dba2a404b4b1219df!1-BC575AB8E2AB9833!2201/content?publicAuth=true&amp;mimeType=image/png\" data-fullres-src-type=\"image/png\">\n\t\t\t<br>\n\t\t\t<h2 lang=\"ko-KR\" style=\"font-size:14pt;color:#2e75b5;margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Malgun Gothic\">&#xC2E4;&#xC81C;</span><span lang=\"en-US\"> </span><span style=\"font-family:Malgun Gothic\">&#xC791;&#xC131;&#xD588;&#xB358;</span><span lang=\"en-US\"> Full Code</span></h2>\n\t\t\t<br>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">&gt;&gt;&gt; import tensorflow as tf</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">&gt;&gt;&gt; x_train = [1,2,3]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">&gt;&gt;&gt; y_train = [1,2,3]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">&gt;&gt;&gt; W = tf.Variable(tf.random_normal([1]), name=&apos;weight&apos;)</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">&gt;&gt;&gt; b = tf.Variable(tf.random_normal([1]), name=&apos;bias&apos;)</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">&gt;&gt;&gt; hypothesis = x_train * W + b</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">&gt;&gt;&gt; cost = tf.reduce_mean(tf.square(hypothesis - y_train))</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">&gt;&gt;&gt; optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">&gt;&gt;&gt; train = optimizer.minimize(cost)</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">&gt;&gt;&gt; sess = tf.Session()</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">2018-02-03 12:37:08.182417: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">&gt;&gt;&gt; sess.run(tf.global_variables_initializer())</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">&gt;&gt;&gt; for step in range(2001):</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">... </span><span lang=\"en-US\" style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">&#xA0; &#xA0; </span><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">sess.run(train)</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">... </span><span lang=\"en-US\" style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">&#xA0; &#xA0; </span><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">if step % 20 == 0:</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">... </span><span lang=\"en-US\" style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">&#xA0; &#xA0; &#xA0; &#xA0; &#xA0; &#xA0; </span><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">print(step, sess.run(cost), sess.run(W), sess.run(b))</span></p>\n\t\t\t<br>\n\t\t\t<h2 lang=\"ko-KR\" style=\"font-size:14pt;color:#2e75b5;margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Malgun Gothic\">&#xC2E4;&#xD589;&#xACB0;&#xACFC;</span></h2>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">0 3.713712 [0.02278715] [0.2002644]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">20 0.06962725 [0.7077251] [0.47195536]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">40 0.033287223 [0.7823072] [0.47654152]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">60 0.029960474 [0.7983317] [0.45669454]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">80 0.027208129 [0.808361] [0.43547428]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">100 0.024710855 [0.8174199] [0.41503173]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">120 0.02244278 [0.82600546] [0.395529]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">140 0.020382902 [0.834183] [0.37694082]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">160 0.018512083 [0.84197587] [0.35922602]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">180 0.01681295 [0.8494024] [0.34234372]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">200 0.015269786 [0.85647994] [0.32625479]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">220 0.013868277 [0.8632249] [0.310922]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">240 0.012595397 [0.86965275] [0.2963099]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">260 0.011439345 [0.87577856] [0.28238443]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">280 0.010389394 [0.88161653] [0.26911345]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">300 0.00943583 [0.88718003] [0.25646618]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">320 0.008569776 [0.89248216] [0.24441324]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">340 0.007783193 [0.89753515] [0.23292676]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">360 0.007068824 [0.9023506] [0.22198005]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">380 0.0064200214 [0.9069397] [0.21154784]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">400 0.00583077 [0.9113132] [0.20160589]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">420 0.0052955956 [0.91548115] [0.19213118]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">440 0.0048095514 [0.9194533] [0.18310168]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">460 0.0043681073 [0.92323864] [0.17449658]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">480 0.003967175 [0.92684615] [0.16629589]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">500 0.0036030663 [0.9302841] [0.15848066]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">520 0.0032723574 [0.9335605] [0.15103266]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">540 0.0029720112 [0.93668294] [0.14393467]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">560 0.0026992324 [0.9396585] [0.1371703]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">580 0.002451485 [0.9424944] [0.13072379]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">600 0.0022264798 [0.945197] [0.12458024]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">620 0.002022121 [0.9477725] [0.11872541]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">640 0.0018365212 [0.95022696] [0.11314581]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">660 0.0016679593 [0.95256615] [0.10782836]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">680 0.0015148661 [0.95479536] [0.10276081]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">700 0.001375829 [0.95691985] [0.09793143]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">720 0.0012495482 [0.9589444] [0.09332903]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">740 0.0011348572 [0.9608739] [0.08894292]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">760 0.0010307012 [0.96271265] [0.08476292]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">780 0.00093610043 [0.964465] [0.08077938]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">800 0.00085018 [0.96613497] [0.07698306]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">820 0.00077214325 [0.9677265] [0.07336518]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">840 0.0007012772 [0.9692432] [0.06991728]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">860 0.0006369103 [0.97068876] [0.06663139]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">880 0.0005784516 [0.9720662] [0.06349993]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">900 0.00052535906 [0.973379] [0.06051568]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">920 0.0004771402 [0.97463024] [0.05767165]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">940 0.0004333457 [0.97582245] [0.05496129]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">960 0.00039357066 [0.9769587] [0.0523783]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">980 0.0003574485 [0.9780415] [0.04991673]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1000 0.00032464007 [0.9790734] [0.04757087]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1020 0.00029484302 [0.9800569] [0.04533525]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1040 0.0002677821 [0.9809942] [0.04320465]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1060 0.00024320187 [0.98188746] [0.04117415]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1080 0.00022088036 [0.9827387] [0.03923912]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1100 0.00020060735 [0.98354983] [0.03739504]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1120 0.00018219619 [0.9843229] [0.03563761]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1140 0.00016547373 [0.9850597] [0.03396281]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1160 0.00015028403 [0.9857619] [0.03236667]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1180 0.00013649119 [0.986431] [0.03084555]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1200 0.00012396318 [0.9870687] [0.02939592]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1220 0.00011258564 [0.9876764] [0.02801441]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1240 0.00010225103 [0.98825556] [0.02669785]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1260 9.286816e-05 [0.98880756] [0.02544314]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1280 8.4343854e-05 [0.98933345] [0.02424742]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1300 7.660236e-05 [0.9898347] [0.02310794]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1320 6.95713e-05 [0.9903125] [0.022022]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1340 6.318514e-05 [0.9907678] [0.02098702]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1360 5.7386787e-05 [0.9912017] [0.02000071]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1380 5.212003e-05 [0.9916152] [0.01906073]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1400 4.7335576e-05 [0.9920092] [0.01816494]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1420 4.299082e-05 [0.9923848] [0.01731124]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1440 3.90451e-05 [0.9927426] [0.01649767]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1460 3.5461682e-05 [0.9930837] [0.01572235]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1480 3.220665e-05 [0.99340874] [0.01498345]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1500 2.9250457e-05 [0.9937185] [0.01427927]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1520 2.6565473e-05 [0.9940137] [0.0136082]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1540 2.4127477e-05 [0.99429506] [0.01296867]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1560 2.1912982e-05 [0.99456316] [0.01235919]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1580 1.9901623e-05 [0.9948187] [0.01177835]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1600 1.8075167e-05 [0.9950623] [0.01122481]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1620 1.641594e-05 [0.99529433] [0.01069723]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1640 1.4908433e-05 [0.99551547] [0.01019447]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1660 1.3540203e-05 [0.9957262] [0.00971535]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1680 1.2297666e-05 [0.9959271] [0.00925876]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1700 1.1168816e-05 [0.9961185] [0.00882361]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1720 1.0143584e-05 [0.99630094] [0.00840892]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1740 9.212734e-06 [0.99647474] [0.00801373]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1760 8.367361e-06 [0.9966404] [0.00763713]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1780 7.5992216e-06 [0.9967983] [0.00727822]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1800 6.9017074e-06 [0.9969488] [0.00693617]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1820 6.2684885e-06 [0.9970922] [0.00661019]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1840 5.693173e-06 [0.9972288] [0.00629954]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1860 5.170363e-06 [0.9973591] [0.00600348]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1880 4.6960135e-06 [0.99748313] [0.00572136]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1900 4.265188e-06 [0.9976014] [0.0054525]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1920 3.8732032e-06 [0.99771416] [0.00519625]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1940 3.5180622e-06 [0.99782157] [0.00495204]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1960 3.1948596e-06 [0.997924] [0.00471931]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">1980 2.9017058e-06 [0.99802154] [0.00449752]</span></p>\n\t\t\t<p lang=\"ko-KR\" style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Monaco;font-size:9pt;color:white;background-color:#282a36\">2000 2.6356656e-06 [0.99811447] [0.00428616]</span></p>\n\t\t\t<br>\n\t\t\t<h2 lang=\"ko-KR\" style=\"font-size:14pt;color:#2e75b5;margin-top:0pt;margin-bottom:0pt\"><span style=\"font-family:Malgun Gothic\">&#xACB0;&#xACFC;&#xC124;&#xBA85;</span></h2>\n\t\t\t<img alt=\"tensorflow tf \n# X and Y data \nx_traln (1, 2, \ny_train [i, 2, 3] \n# Our hypothesis xw.b \nhyX1thesis x_train &#x2022; b \n# cost/loss function \nFull \ncode (less th \nn.a&#x2014;z weight &#x2022; ) \nnae&#x2014; &#x2022; bias &apos; ) \ncost &#x2022; y_traln)) \nMinimize \noptimizer \n# Launch the graph in a session. \nsess &#x2022; tf.Session() \nInitial izes ql&apos;*at variables in the graph \ne 2.82329 ( \n351 \nae &#xF8;.1S13S7 \n2.12867713) \nt 1.4572546! \" width=\"480\" height=\"263.5\" src=\"https://www.onenote.com/api/v1.0/me/notes/resources/0-393dc4cb154f18408619756bddb497e3!1-BC575AB8E2AB9833!2201/content?publicAuth=true&amp;mimeType=image/png\" data-src-type=\"image/png\" data-fullres-src=\"https://www.onenote.com/api/v1.0/me/notes/resources/0-393dc4cb154f18408619756bddb497e3!1-BC575AB8E2AB9833!2201/content?publicAuth=true&amp;mimeType=image/png\" data-fullres-src-type=\"image/png\">\n\t\t\t<br>\n\t\t\t<br>\n\t\t\t<br>\n\t\t\t<h1 style=\"font-size:16pt;color:#1e4e79;margin-top:0pt;margin-bottom:0pt\">Case 2. placeholder<span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xB97C;</span> <span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xC0AC;&#xC6A9;&#xD574;&#xC11C;</span> <span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xAD6C;&#xD604;&#xD558;&#xAE30;</span></h1>\n\t\t\t<br>\n\t\t\t<h3 style=\"color:#5b9bd5;margin-top:0pt;margin-bottom:0pt\">[pic1]</h3>\n\t\t\t<img alt=\"X and \nY data \ntrain = \nx \ny _ train = \nPlaceholders \nNow we can use X and Y in place of x_data and y_data \n# placeholders for a tensor that will be always fed us \nSee http://stackoverfLow. com/questions/3669374&#xD8;/ \nUplaceh01der(tf.f10at32) \n# Fit the Line \n# Fit the Line \nfor step in range(2&#xF8;&#xF8;1): \" width=\"480\" height=\"316.5\" src=\"https://www.onenote.com/api/v1.0/me/notes/resources/0-2b38cdd3d8dc9043bbb67c11753380c1!1-BC575AB8E2AB9833!2201/content?publicAuth=true&amp;mimeType=image/png\" data-src-type=\"image/png\" data-fullres-src=\"https://www.onenote.com/api/v1.0/me/notes/resources/0-2b38cdd3d8dc9043bbb67c11753380c1!1-BC575AB8E2AB9833!2201/content?publicAuth=true&amp;mimeType=image/png\" data-fullres-src-type=\"image/png\">\n\t\t\t<br>\n\t\t\t<br>\n\t\t\t<h3 lang=\"ko-KR\" style=\"color:#5b9bd5;margin-top:0pt;margin-bottom:0pt\">[pic2]</h3>\n\t\t\t<p style=\"margin-top:0pt;margin-bottom:0pt\"><span style=\"font-weight:bold\">[None]</span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic;font-weight:bold\">&#xC758;</span><span style=\"font-family:Malgun Gothic;font-weight:bold\"> </span><span lang=\"ko-KR\" style=\"font-weight:bold\">None :</span><span lang=\"ko-KR\"> </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xC544;&#xBB34;</span><span style=\"font-family:Malgun Gothic\"> </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xAC12;&#xC774;&#xB098;</span><span style=\"font-family:Malgun Gothic\"> </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xC640;&#xB3C4;</span><span style=\"font-family:Malgun Gothic\"> </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xB41C;&#xB2E4;&#xB294;</span><span style=\"font-family:Malgun Gothic\"> </span><span lang=\"ko-KR\" style=\"font-family:Malgun Gothic\">&#xB73B;</span><span style=\"font-family:Malgun Gothic\">.</span></p>\n\t\t\t<img alt=\"tensorflow as tf \nH tf.variable(tf. ) \nb tf.Variab1e(tf. nanez&#x2022;bias &#x2022; ) \nimport \ntf.placeholder(tf .f10at32, shape: [None)) \nY tf.p1aceh01der(tf.f10at32, \n# Our hypothesis XW+b \nhypothesis X &#x2022; W + b \n# cost/toss function \ncost = square(hypothesis - Y)) \n# hinimize \nFull code with p \n1960 3.323960-07 [ 1.00( \n1980 2.90429e-07 [ 1.0M \noptimizer = tf. 00 2.2227 ( 1.000: \ntrain = optimizer.minimize(cost) \n# Launch the graph in a session. \nsess = tf.Session() \n# Initializes global variables in the graph. \nsess. run(tf. izer( ) ) \nFit the Line &#x2022;ith new training data \n# Testing our model \nprint( sess . run(hypotm \nprint ( sess . run(hypotru \nprint ( hypotm \" width=\"480\" height=\"270\" src=\"https://www.onenote.com/api/v1.0/me/notes/resources/0-2785c139f4265a43a7ea6a054e564783!1-BC575AB8E2AB9833!2201/content?publicAuth=true&amp;mimeType=image/png\" data-src-type=\"image/png\" data-fullres-src=\"https://www.onenote.com/api/v1.0/me/notes/resources/0-2785c139f4265a43a7ea6a054e564783!1-BC575AB8E2AB9833!2201/content?publicAuth=true&amp;mimeType=image/png\" data-fullres-src-type=\"image/png\">\n\t\t\t<br>\n\t\t</div>\n\t\n\n"}}}